{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometric meaning:\n",
    "The SVM tries to find the maximum margin hyperplane that separates the two classes $(y_i = 1 or -1)$.\n",
    "The hyperplane is $w^T x + b = 0$. \n",
    "We want to maximize the margin (distance between hyperplane and closest points).\n",
    "The $\\xi_i$ are slack variables that allow some points to be within the margin or misclassified. The $f(\\xi_i)$ penalizes this.\n",
    "\n",
    "\n",
    "Dual problem:\n",
    "Lagrangian: \n",
    "$L(w,b,\\xi,\\alpha,\\mu) = 1/2|w|^2 + C\\sum_i f(\\xi_i) - \\sum_i \\alpha_i [ y_i(w^T x_i + b) - 1 + \\xi_i] - \\sum_i \\mu_i \\xi_i$\n",
    "\n",
    "Take derivatives wrt primal variables w,b,\\xi and set to 0: \n",
    "\n",
    "$w = \\sum_i \\alpha_i y_i x_i $\n",
    "\n",
    "$\\sum_i \\alpha_i y_i = 0 $\n",
    "\n",
    "$Cf'(\\xi_i) - \\alpha_i - \\mu_i = 0$\n",
    "\n",
    "Substitute back into Lagrangian: \n",
    "\n",
    "$L(\\alpha) = -\\frac{1}{2}\\sum_{i,j} \\alpha_i \\alpha_j y_i y_j (x_i^T x_j) + \\sum_i \\alpha_i$\n",
    "s.t. $\\alpha_i >= 0$ and $\\sum_i \\alpha_i y_i = 0$\n",
    "\n",
    "So the dual problem is: \n",
    "\n",
    "$max_\\alpha -\\frac{1}{2}\\sum_{i,j} \\alpha_i \\alpha_j y_i y_j (x_i^T x_j) + \\sum_i \\alpha_i s.t. \\alpha_i >= 0, \\sum_i \\alpha_i y_i = 0$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
